<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Raw WebGL</title>
    <meta name="description" content="Introduction to WebGL">
    <meta name="author" content="Nick Desaulniers">
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link rel="stylesheet" href="css/reveal.min.css">
    <link rel="stylesheet" href="css/theme/simple.css" id="theme">
    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">
    <!-- If the query includes 'print-pdf', use the PDF print sheet -->
    <script>
      document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
    </script>
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="reveal">
      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section>
          <h1>Raw WebGL</h1>
          <p>Nick Desaulniers</p>
        </section>
        <section>
          <h2>Nick Desaulniers</h2>
          <p>Open Source Zealot at Mozilla</p>
          <img src="nick_face.jpg"/><br/>
          <p>Organized NSA protest in San Francisco</p>
          <p>Spoke About the Evils of Software Patents on NPR</p>
        </section>
        <section>
          <h3>There's more to JS than jQuery</h3>
          <h3>There's more to WebGL than Three.js</h3>
        </section>
        <section>
          <h2>Warning</h2>
          <p>Graphics programming is a rabbit hole that is infinitely deep</p>
          <img src="books.png"/>
        </section>
        <section>
          <h2>Warning</h2>
          <p>
            Graphics programming is equal parts physics (how do I accurately
            model the physical phenomina that I am seeing) and computer science
            (how do I calculate all this math and still hit 16.66ms).
          </p>
          <p class="fragment">
            It's all that math you learned but never had a chance to apply.
          </p>
          <ul>
            <li class="fragment">Geometry</li>
            <li class="fragment">Trigonometry</li>
            <li class="fragment">Linear Algebra</li>
          </ul>
        </section>
        <section>
          <h2>History</h2>
          <img src="history.jpg"/>
          <img src="opengl.png"/>
          <img src="opengles.png"/>
          <img src="webgl.png"/>
          <img src="khronos.png"/>
        </section>
        <section>
          <h2>Pipeline</h2>
          <img src="pipeline.gif"/>
        </section>
        <section>
          <h2>What goes into a WebGL</h2>
          <h2>Application?</h2>
          <img src="goesin.jpg">
          <p>All of these are optional except a single shader pair</p>
        </section>
        <section>
          <h2>Terminology</h2>
        </section>
        <section>
          <h2>Vertex</h2>
          <img src="vertex.png"/><br/>
          <p><i>A special kind of point that describes the corners or intersections of geometric shapes.</i></p>
        </section>
        <section>
          <h2>Polygon</h2>
          <img src="polygon.png"/><br/>
          <p><i>A figure bounded by edges, and the points where two edges meet are the polygon's vertices.</i></p>
        </section>
        <section>
          <h2>Mesh</h2>
          <img src="mesh.png"/><br/>
          <p><i>A polygon mesh is a collection of vertices, edges and faces that defines the shape of a polyhedral object in 3D computer graphics and solid modeling.  AKA Geometric Model.</i></p>
        </section>
        <section>
          <h2>Triangles</h2>
          <p>Why do we use triangles, as opposed to squares (aka quads)?</p>
          <p class="fragment"><i>The vertices of a triangle are guaranteed to lie along the same plane.</i></p>
        </section>
        <section>
          <h2>Buffer</h2>
          <img src="buffer.png"/><br/>
          <p><i>A data buffer is a region of a memory used to temporarily store data while it is being moved from one place to another.</i></p>
        </section>
        <section>
          <h2>Affine Transformation</h2>
          <p><i>A function between affine spaces which preserves points, straight lines, and planes.  Parallel lines stay parrallel.  Doesn't preserve angles or distances, but does for ratios between points lying on a straight line.</i></p>
        </section>
        <section>
          <h2>Translate</h2>
          <img src="translation.png"/><br/>
        </section>
        <section>
          <h2>Rotate</h2>
          <img src="rotation.png"/><br/>
        </section>
        <section>
          <h2>Scale</h2>
          <img src="scaling.png"/><br/>
         </section>
         <section>
          <h2>Homogenous Coordinates</h2>
          <p>p(x, y, z, w) allows us to:</p>
          <p class="fragment">Represent infinite distances as (x/w, y/w, z/w)  as
          w -&gt; 0 which allows us to do perspective transformations.</p>
          <p class="fragment">Compose transformations as a series of matrix multiplications.</p>
        </section>
        <section>
          <h2>Perspective</h2>
          <img src="perspective.jpg"/><br/>
          <p>Does the right side of the road eventually touch the left side?</p>
          <p>Are the trees getting shorter?</p>
        </section>
        <section>
          <h2>Frustrum</h2>
          <img src="frustrum.png"/><br/>
          <p><i>The portion of a solid (normally a cone or pyramid) that lies between two parallel planes cutting it.</i></p>
        </section>
        <section>
          <h2>Viewing Frustum</h2>
          <img src="viewFrustum.png"/><br/>
          <p>AKA Field of View</p>
        </section>
        <section>
          <h2>Bitmap</h2>
          <img src="bitmap.png"/><br/>
          <p><i>A data structure representing a rectangular grid of pixels, or points of color, viewable via a display medium.</i></p>
        </section>
        <section>
          <h2>Textures</h2>
          <img src="texture.gif"/><br/>
          <p><i>A bitmap that will later be applied or mapped onto a mesh or model.</i></p>
        </section>
        <section>
          <h2>Sampling</h2>
          <img src="sampling.png"/><br/>
          <p><i>The reduction of a continuous signal to a discrete signal.</i></p>
          <p>Allows us to quickly approximate an integral.</p>
        </section>
        <section>
          <h2>Rasterization</h2>
          <p><i>The process to convert shapes, defined in a vector format into fragments (pixels or dots) for display on a video screen.</i></p>
        </section>
        <section>
          <h2>Fragment</h2>
          <img src="fragment.png"/><br/>
          <p><i>The pixel generated by the rasterization process process which has color, depth, value, texture coordinates, and more.</i></p>
        </section>
        <section>
          <h2>Frame</h2>
          <p><i>One of the many still images which compose the complete moving picture; each image looks rather like a framed picture when examined individually.</i></p>
        </section>
        <section>
          <h2>Real Time Rendering</h2>
          <img src="realtime.png"/><br/>
          <p><i>Doing the rendering computation fast enough, so that the series of rendered images allow for interaction taking into account user input.</i></p>
          <ul>
            <li>30 fps = 33.3 ms</li>
            <li>60 fps = 16.6 ms</li>
            <li>90 fps = 11.1 ms</li>
          </ul>
        </section>
        <section>
          <h2>Pre Rendering</h2>
          <img src="ts3.jpg"/><br/>
          <p>Opposite of real time rendering.</p>
          <p><a href="http://www.wired.com/2010/05/process_pixar/all/">Toy Story 3</a> took on average 7 hours to render 1 frame (24 fps), and at most 39 hours.</p>
        </section>
        <section>
          <h2>Shading</h2>
          <img src="preshade.png"><img src="postshade.png">
          <p><i>Depicting depth perception in 3D models by varying levels of darkness.</i></p>
        </section>
        <section>
          <h2>Material</h2>
          <p><i>A shader program that implments a scattering function for a set of polygons.</i></p>
        </section>
        <section>
          <h2>Shaders</h2>
          <p>Small programs that run massively parallel on the GPU.</p>
          <p class="fragment">Shaders come in pairs (for now) of vertex and fragment.</p>
          <p class="fragment">A vertex shader can feed a fragment shader.</p>
          <p class="fragment">Shaders can be mixed and matched if the have the same output to input.</p>
          <p class="fragment">Vertex shaders are run for each vertex.</p>
          <p class="fragment">Fragment shaders are run for each fragment, with color values being interpolated inbetween.</p>
        </section>
        <section>
          <img src="2dcoords.png"/>
          <p>Also, the DOM.</p>
        </section>
        <section>
          <img src="3dcoords.png"/><br/>
          <p>Anything outside of the 2x2x2 box is culled (doesn't get drawn).</p>
        </section>
        <section>
          <img src="texcoords.png"/><br/>
          <p>For all sizes of images, (1, 1) represents top right.</p>
          <p>Most bitmaps store the inverse vertical axis.</p>
          <p>readPixels assumes lower left origin.<p>
        </section>
        <section>
          <h2>The Canvas</h2>
          <pre><code>
<canvas id="my_canvas" width="400" height="400">
  Oops, your browser doesn't support html5 canvas!
</canvas>
          </code></pre>
        </section>
        <section>
          <h2>Getting a WebGL Context</h2>
          <pre><code class="language-javascript">
var canvas = document.getElementById('my_canvas');
var gl = canvas.getContext('webgl') ||
         canvas.getContext('experimental-webgl');
if (!gl) throw new Error('browser may not support webgl');
          </code></pre>
        </section>
        <section>
          <h2>Clearing the Canvas</h2>
          <pre><code class="language-javascript">
gl.clearColor(0.0, 0.0, 0.0, 1.0);
gl.clear(gl.COLOR_BUFFER_BIT);
          </code></pre>
          <a href="clear.html" target="_blank">Example</a>
        </section>
        <section>
          <h2>Baby's First Shaders</h2>
          <p>Vertex Shader</p>
          <pre><code>
attribute vec4 aPosition;
void main () {
  gl_Position = aPosition;
  gl_PointSize = 10.0;
}
          </code></pre>
          <p>Fragment Shader</p>
          <pre><code>
precision mediump float;
uniform vec4 uFragColor;
void main () {
  gl_FragColor = uFragColor;
}
          </code></pre>
          <p>Written in GLSL</p>
        </section>
        <section>
          <h2>Attributes and Uniforms</h2>
          <p class="fragment">Uniforms and Attributes are inputs to shaders.</p>
          <p class="fragment">Uniforms are the same (uniform) for all vertices.</p>
          <p class="fragment">Attributes are unique per vertex.</p>
          <p class="fragment">Attributes are only inputs to vertex shaders.</p>
          <p class="fragment">Vertex shaders can output to fragment shaders via varyings.</p>
        </section>
        <section>
          <h2>Compile Shaders</h2>
          <pre><code class="language-javascript">
function compile (gl, type, shaderSrc) {
  var shader = gl.createShader(type);
  gl.shaderSource(shader, shaderSrc);
  gl.compileShader(shader);

  if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
    throw new Error(gl.getShaderInfoLog(shader));
  }

  return shader;
};
var vertexShader = compile(gl, gl.VERTEX_SHADER,
                           vertexShaderSrc);
var fragmentShader = compile(gl, gl.FRAGMENT_SHADER,
                            fragmentShaderSrc);
          </code></pre>
        </section>
        <section>
          <h2>Link Shaders</h2>
          <pre><code class="language-javascript">
function link (gl, vertexShader, fragmentShader) {
  var program = gl.createProgram();
  gl.attachShader(program, vertexShader);
  gl.attachShader(program, fragmentShader);
  gl.linkProgram(program);

  if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
    throw new Error(gl.getProgramInfoLog(program));
  }

  return program;
};
var program = link(gl, vertexShader, fragmentShader);
gl.useProgram(program);
          </code></pre>
          <p>A 3D application may use more than one gl program.</p>
          </section>
          <section>
            <h2>Getting References to</h2>
            <h2>Uniforms and Attributes</h2>
            <pre><code class="language-javascript">
var aPosition = gl.getAttribLocation(program, 'aPosition');
var uFragColor = gl.getUniformLocation(program, 'uFragColor');
            </code></pre>
          </section>
          <section>
            <h2>Setting Uniforms and</h2>
            <h2>Attributes Directly</h2>
            <pre><code class="language-javascript">
gl.vertexAttrib2f(aPosition, 0.0, 0.0);
gl.uniform4f(uFragColor, 1.0, 0.0, 0.0, 1.0);
            </code></pre>
          </section>
          <section>
            <h2>Draw</h2>
            <pre><code class="language-javascript">
// takes a mode, first, count
gl.drawArrays(gl.POINTS, 0, 1);
            </code></pre>
            <a href="examples/point.html" target="_blank">Example</a>
          </section>
          <section>
            <h2>Separation of Concerns</h2>
            <p>Move shaders from HTML or JS into their own files, load with XHR.</p>
            <p class="fragment">Though, we can do cool tricks by procedurally generating
            strings of shaders at runtime.</p>
          </section>
          <section>
            <h2>Reflection</h2>
            <p>
              We can use reflection of a gl program to get references to its
              attributes and uniforms. This step is not strictly necessary, but
              can help you get references when shaders have many inputs.
            </p>
            <pre><code class="language-javascript">
var numAttributes = gl.getProgramParameter(program, gl.ACTIVE_ATTRIBUTES);
for (var i = 0; i < numAttributes; ++i) {
  gl.getAttribLocation(program, gl.getActiveAttrib(program, i).name);
}

var numUniforms = gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS);
for (i = 0; i < numUniforms; ++i) {
  gl.getUniformLocation(program, gl.getActiveUniform(program, i).name);
}
            </code></pre>
          </section>
          <section>
            <h2>Modularize and Reuse</h2>
            <p>
              Move compile, link, reflection, and other  helper functions into
              reusable file.
            </p>
            <a href="examples/point_clean.html" target="_blank">Example</a>
          </section>
          <section>
            <h2>Drawing Points</h2>
            <p>First, we need to beef up our shaders.</p>
            <pre><code>
attribute vec4 aPosition;
attribute float aPointSize;
attribute vec4 aColor;
varying vec4 vColor;

void main () {
  gl_Position = aPosition;
  gl_PointSize = aPointSize;
  vColor = aColor;
}
            </code></pre>
            <pre><code>
precision mediump float;
varying vec4 vColor;

void main () {
  gl_FragColor = vColor;
}
            </code></pre>
          </section>
          <section>
            <h2>Multiple Draw Calls</h2>
            <p>
              As a naive first attempt, let's draw each point with its own draw
              call.
            </p>
            <pre><code class="language-javascript">
var p = [
  { x:  0.0, y:  0.5, sz: 10.0, r: 1.0, g: 0.0, b: 0.0 },
  { x: -0.5, y: -0.5, sz: 20.0, r: 0.0, g: 1.0, b: 0.0 },
  { x:  0.5, y: -0.5, sz: 30.0, r: 0.0, g: 0.0, b: 1.0 }
];
for (var i = 0; i < p.length; ++i) {
  gl.vertexAttrib4f(attributes.aPosition, p[i].x, p[i].y, 0.0, 1.0);
  gl.vertexAttrib1f(attributes.aPointSize, p[i].sz);
  gl.vertexAttrib4f(attributes.aColor, p[i].r, p[i].g, p[i].b, 1.0);
  gl.drawArrays(gl.POINTS, 0, 1);
}
            </code></pre>
            <a href="examples/points_multiple_draw.html" target="_blank">
              Example
            </a>
          </section>
          <section>
            <h2>Multiple Draw Calls</h2>
            <p>Multiple draw calls sometimes are needed to build up a scene.</p>
            <p class="fragment">Draw calls can be the most expensive call.</p>
            <p class="fragment">Try to minimize draw calls.</p>
          </section>
          <section>
            <h2>Multiple Buffers</h2>
            <p>
              Instead, we can push data in multiple buffers to the GPU.
            </p>
            <pre><code class="language-javascript">
function initBuffer (gl, data, elemPerVertex, attribute) {
  var buffer = gl.createBuffer();
  if (!buffer) throw new Error('Failed to create buffer.');
  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
  gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW);
  gl.vertexAttribPointer(attribute, elemPerVertex, gl.FLOAT, false, 0, 0);
  gl.enableVertexAttribArray(attribute);
};
var positions = new Float32Array([0.0, 0.5, -0.5, -0.5, 0.5, -0.5]);
var pointSize = new Float32Array([10.0, 20.0, 30.0]);
var colors = new Float32Array([1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]);
initBuffer(gl, positions, 2, attributes.aPosition);
initBuffer(gl, pointSize, 1, attributes.aPointSize);
initBuffer(gl, colors, 3, attributes.aColor);
            </code></pre>
            <a href="examples/points_multi_buffer.html" target="_blank">Example</a>
          </section>
          <section>
            <h2>Warning</h2>
            <p>
              Copying memory (uploading
              buffers) from the main memory to the video memory can be
              expensive. It can be faster to upload a single
              larger buffer in one go than multiple smaller buffers
              individually.
            </p>
          </section>
          <section>
            <img src="buffer_compare.png"/>
          </section>
          <section>
            <h2>Interleaved Buffer</h2>
            <pre><code class="language-javascript">
var data = new Float32Array([
   0.0,  0.5,   10.0,   1.0, 0.0, 0.0,
  -0.5, -0.5,   20.0,   0.0, 1.0, 0.0,
   0.5, -0.5,   30.0,   0.0, 0.0, 1.0
]);
var bpe = data.BYTES_PER_ELEMENT;
var buffer = gl.createBuffer();
if (!buffer) throw new Error('Failed to create buffer.');
gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW);
gl.vertexAttribPointer(attributes.aPosition, 2, gl.FLOAT, false, 6 * bpe, 0);
gl.enableVertexAttribArray(attributes.aPosition);
gl.vertexAttribPointer(attributes.aPointSize, 1, gl.FLOAT, false, 6 * bpe, 2 * bpe);
gl.enableVertexAttribArray(attributes.aPointSize);
gl.vertexAttribPointer(attributes.aColor, 3, gl.FLOAT, false, 6 * bpe, 3 * bpe);
gl.enableVertexAttribPointer(attributes.aColor);
            </code></pre>
            <a href="examples/points_one_buffer.html" target="_blank">Example</a>
          </section>
          <section>
            <h2>Warning</h2>
            <p>
              What if only some of the data in our buffer is changing every
              frame of animation?
            </p>
            <p class="fragment">It might be wiser to use multiple buffers instead of interleaved.</p>
            <p class="fragment">There is no one right answer; depends on situation.</p>
            <p class="fragment">Profile your app and figure out what works best.</p>
            <p class="fragment">Other tricks like Element Array Buffers can help reduce memory usage.</p>
          </section>
          <section>
            <h2>Drawing Modes</h2>
            <p>gl.drawArrays(mode, start, numVertices) can take:</p>
            <ul>
              <li>gl.POINTS</li>
              <li>gl.LINES</li>
              <li>gl.LINE_STRIP</li>
              <li>gl.LINE_LOOP</li>
              <li>gl.TRIANGLES</li>
              <li>gl.TRIANGLE_STRIP</li>
              <li>gl.TRIANGLE_FAN</li>
            </ul><br/>
            <a href="examples/draw_modes.html" target="_blank">Example</a>
          </section>
          <section>
            <h2>Perspective</h2>
            <p>In order to properly draw a 3D scene in perspective we need 3 things:</p>
            <ol>
              <li class="fragment">Matrix of our model's transformations relative to its original coords. (Model Matrix)</p>
              <li class="fragment">Matrix of where we are relative to model, where we are looking, and the up direction. (View Matrix)</p>
              <li class="fragment">Matrix decribing viewing angle, aspect ratio, and near and far clipping plane of our viewing frustum. (Projection Matrix)</p>
            </ol>
            <a href="examples/mvp.html" target="_blank" class="fragment">Examples</a>
          </section>
          <section>
            <h2>Animation</h2>
            <pre><code class="language-javascript">
function animate (time) {
  // update
  mat4.rotateY(modelMatrix, modelMatrix, Math.PI / 180);
  gl.uniformMatrix4fv(modelUniform, false, modelMatrix);

  // render
  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
  gl.drawArrays(gl.TRIANGLES, 0, n);
  requestAnimationFrame(animate);
};
            </code></pre>
            <a href="examples/animation.html" target="_blank">Example</a>
          </section>
          <section>
            <h2>Textures</h2>
            <h4>Initialization</h4>
            <pre><code class="language-javascript">
var texture = gl.createTexture();
gl.activeTexture(gl.TEXTURE0);
gl.bindTexture(gl.TEXTURE_2D, texture);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
gl.uniform1i(uSampler, 0);
            </code></pre>
          </section>
          <section>
            <h2>Textures</h2>
            <h4>Sampling</h4>
            <pre><code class="language-javascript">
gl.bindTexture(gl.TEXTURE_2D, texture);
gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, 1);
gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE,
               imgArrayBufferViewVideoOrCanvas);
            </code></pre>
            <p>Can be done during initialization for static images.</p>
            <p>Must be done during requestAnimationFrame loop for video.</p>
            <p>Must be done when limited on texture units per draw call.</p>
            <a href="examples/texture.html" target="_blank">Example</a>
          </section>
          <section>
            <h2>Warning</h2>
            <p>Uploading textures to the GPU can be expensive.</p>
            <p>Try to minimize texture swapping between frames.<p>
          </section>
          <section>
            <h2>Shading</h2>
            <h4>Interpolation Techniques</h4>
            <p>Flat shading - Each polygon has its own color - Disco Ball</p>
            <p>Gouraud shading - Normals at each vertex - Mach Bands</p>
            <p>Phong shading - Interpolate normals across surface</p>
            <img src="flat.jpg"/>
          </section>
          <section>
            <h2>Shading</h2>
            <h4>Illumination Models</h4>
            <p>Lambert - The shade is the cosine of the angle between surface normal and light vector.</p>
            <p>Blinn-Phong - The shade is composed of a specular, diffuse, ambient, and shininess components of the material.</p>
            <img src="phong.png"/>
          </section>
          <section>
            <h2>Shading</h2>
            <p>All of this can be done with what you now know.</p>
            <p>Light directions and material reflective coefficients are buffered.</p>
            <p>Calculations done in shaders.</p>
            <p>Exercise left to the reader.</p>
          </section>
          <section>
            <h2>Recommended Reading</h2>
            <img src="webgl_book.jpg"/><br/>
            <p><a href="http://fabiensanglard.net/Computer_Graphics_Principles_and_Practices/index.php" target="_blank">More recommendations</a></p>
          </section>
          <section>
            <h2>Inspiration</h2>
            <p>Tony Parasi</p>
            <p><a href="http://www.youtube.com/watch?v=me3BviH3nZc" target="_blank">Eric MÃ¶ller</a></p>
            <p><a href="https://github.com/gameclosure/webgl-2d" target="_blanks">webgl-2d</a></p>
          </section>
          <section>
            <h2>Thanks</h2>
            <img src="nick_face.jpg"/>
            <p>Nick Desaulniers</p>
            <p><a href="https://twitter.com/LostOracle" target="_bank">@LostOracle</a> on Twitter</p>
            <p>\n on mozilla.irc.org</p>
            <p><a href="https://github.com/nickdesaulniers" target="_bank">nickdesaulniers</a> on GitHub</p>
            <p><a href="http://nickdesaulniers.github.io/" target="_bank">nickdesaulniers.github.io</a>-&gt; blog</p>
          </section>
       </section>
      </div>
    </div>
    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.min.js"></script>
    <script>
      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
        transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none
        // Parallax scrolling
        // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
        // parallaxBackgroundSize: '2100px 900px',

        // Optional libraries used to extend on reveal.js
        dependencies: [
        { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
        //{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        //{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
        //{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
        //{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
        ]
      });
    </script>
    <script>
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-36993986-1']);
      _gaq.push(['_trackPageview']);

      (function() {
       var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
       ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
       var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
       })();
    </script>
  </body>
</html>

